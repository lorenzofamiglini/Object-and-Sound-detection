{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dei pacchetti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "import keras as ks\n",
    "from keras.preprocessing import image as kimage\n",
    "import skimage.io as io\n",
    "import random\n",
    "import sys\n",
    "import pickle as pkl\n",
    "from imblearn.keras import BalancedBatchGenerator\n",
    "from keras.utils import np_utils\n",
    "lib_path = os.path.join(os.path.realpath(r\"C:\\Users\\Giobi\\OneDrive - Universita degli Studi di Milano-Bicocca\\Digital Signal and Image Management\\Progetto Segnali Stradali\\DataAugmentationForObjectDetection-master\"), \"data_aug\")\n",
    "sys.path.append(lib_path)\n",
    "from bbox_util import *\n",
    "from data_aug import *\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Concatenate,Input, Dense, Flatten, Reshape, MaxPooling2D, Conv2D, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Activation, Dense, Dropout, BatchNormalization, LeakyReLU\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, explained_variance_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.utils import shuffle\n",
    "import skimage.measure\n",
    "from scipy.spatial import distance\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funzioni utili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_only_one_signal(results, euclidean):\n",
    "    is_sig = 0.6\n",
    "    diz = {}\n",
    "    conta = 0\n",
    "    ob = np.squeeze(results)\n",
    "    #print(type(ob))\n",
    "    #print(ob.shape)\n",
    "    if ob.shape == ():\n",
    "        ob = np.array([ob])\n",
    "    if (len(ob.shape)==1)&(results.shape[1]<=results.shape[2]):\n",
    "        ob = np.expand_dims(ob, axis = 0)\n",
    "    if (len(ob.shape)==1)&(results.shape[1]>results.shape[2]):\n",
    "        ob = np.expand_dims(ob, axis = 1)\n",
    "    #print(ob.shape)\n",
    "    for i in range(0, ob.shape[0]):\n",
    "        for j in range(0, ob.shape[1]):\n",
    "            if ob[i][j] > 0.6:\n",
    "                close = False\n",
    "                for k in diz:\n",
    "                    if (distance.euclidean([i,j], [diz[k]['i'],diz[k]['j']]) <= euclidean):\n",
    "                        #print('troppo vicino: ' + str((i,j)) + ' da ' + str(((diz[k]['i']),(diz[k]['j']))), 'la distanza è: ' + str(distance.euclidean([i,j], [diz[k]['i'],diz[k]['j']])))\n",
    "                        close = True\n",
    "                        if (diz[k]['value']<ob[i][j]):\n",
    "                            diz[k]['value'] = ob[i][j]\n",
    "                            diz[k]['i'] = i\n",
    "                            diz[k]['j'] = j           \n",
    "                if (close == False):\n",
    "                    d = {}\n",
    "                    d['value'] = ob[i][j]\n",
    "                    d['i'] = i\n",
    "                    d['j'] = j\n",
    "                    diz['n{}'.format(len(diz.keys()))] = d\n",
    "            conta +=1\n",
    "    out = np.zeros([ob.shape[0], ob.shape[1]])\n",
    "    for k in diz:\n",
    "        i = diz[k]['i']\n",
    "        j = diz[k]['j']\n",
    "        out[i][j] = diz[k]['value']\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crops_with_signal(image, results, show = False):\n",
    "    diz = {}\n",
    "    ob = np.squeeze(results)\n",
    "    image = np.squeeze(image)\n",
    "    if (len(ob.shape) == 1) & (image.shape[0]<=image.shape[1]):\n",
    "        for j in range(0, len(ob)):\n",
    "            if np.round(ob[j]) == 1:\n",
    "                window = image[:40, 2*j:40 + 2*j,  :]\n",
    "                d = {}\n",
    "                d['j'] = j\n",
    "                d['prob'] = ob[j]\n",
    "                d['formula'] = 'image[:40, 2*j:40 + 2*j,  :]'\n",
    "                d['array'] = window\n",
    "                diz['im{}'.format(len(diz.keys()))] = d\n",
    "                if show == True:\n",
    "                    plt.imshow(window); plt.show()\n",
    "                    \n",
    "    if (len(ob.shape) == 1) & (image.shape[0]>image.shape[1]):\n",
    "        for j in range(0, len(ob)):\n",
    "            if np.round(ob[j]) == 1:\n",
    "                window = image[2*j:40 + 2*j, :40, :]\n",
    "                d = {}\n",
    "                d['j'] = j\n",
    "                d['prob'] = ob[j]\n",
    "                d['formula'] = 'image[2*j:40 + 2*j, :40, :]'\n",
    "                d['array'] = window\n",
    "                diz['im{}'.format(len(diz.keys()))] = d\n",
    "                if show == True:\n",
    "                    plt.imshow(window); plt.show()\n",
    "                    \n",
    "    if (len(ob.shape) > 1):\n",
    "        for i in range(0, ob.shape[0]):\n",
    "            for j in range(0, ob.shape[1]):\n",
    "                if (np.round(ob[i][j]) == 1):\n",
    "                    window = image[2*i : 40 + 2*i, 2*j:40 + 2*j,  :]\n",
    "                    d = {}\n",
    "                    d['j'] = j\n",
    "                    d['i'] = i\n",
    "                    d['prob'] = ob[i][j]\n",
    "                    d['formula'] = 'image[2*i : 40 + 2*i, 2*j:40 + 2*j,  :]'\n",
    "                    d['array'] = window\n",
    "                    diz['im{}'.format(len(diz.keys()))] = d\n",
    "                    if show == True:\n",
    "                        plt.imshow(window); plt.show()\n",
    "    return diz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_img(im):\n",
    "    multipli40 = np.arange(start = 40, stop = max(im.shape) + 40, step = 40)\n",
    "    index_x = np.argmin(np.absolute(multipli40-im.shape[1]))\n",
    "    new_x = multipli40[index_x]\n",
    "    index_y = np.argmin(np.absolute(multipli40-im.shape[0]))\n",
    "    new_y = multipli40[index_y]\n",
    "    resized = cv2.resize(im, (new_x, new_y), interpolation = cv2.INTER_AREA)\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_img(im):\n",
    "    im = np.expand_dims(im, axis = 0)\n",
    "    r = 0\n",
    "    c = 0\n",
    "    new_im = im[0, 0:40,0:40]\n",
    "    new_im = np.expand_dims(new_im, axis = 0)\n",
    "    for i in range(0, int(im.shape[1]/40)):\n",
    "        for j in range(0, int(im.shape[2]/40)):\n",
    "            if ((i==0)&(j==0)):\n",
    "                new_im = new_im\n",
    "            else:\n",
    "                app = np.expand_dims(im[0, r:r+40, c:c+40], axis = 0)\n",
    "                new_im = np.concatenate([new_im, app], axis = 0)\n",
    "            c = c + 40\n",
    "        r = r + 40\n",
    "        c = 0\n",
    "    return new_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_new_size(im, new_x, new_y):\n",
    "    new_im =  cv2.resize(im, (new_x, new_y), interpolation = cv2.INTER_AREA)\n",
    "    plt.imshow(new_im); plt.show()\n",
    "    new_im = reshape_img(new_im)\n",
    "    return new_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_task_prediction(diz):\n",
    "    for i in diz:\n",
    "        signal, bbox = model_multi_task.predict(np.expand_dims(diz[i]['array'], axis = 0))\n",
    "        signal = np.argmax(signal)\n",
    "        diz[i]['signal'] = df[df['target']==signal]['title']\n",
    "        diz[i]['bbox'] = bbox\n",
    "    return diz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_draw_rect(img, bboxes):\n",
    "    x1 = bboxes[0]\n",
    "    y1 = bboxes[1]\n",
    "    x2 = bboxes[2]\n",
    "    y2 = bboxes[3]\n",
    "    new_bb = np.array([[x1, y1, x2, y2, 0]])\n",
    "    plt.imshow(draw_rect(img, new_bb)); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(diz, im, probability = False):    \n",
    "    for i in diz:\n",
    "        if i!='shape':\n",
    "            if (probability == True):\n",
    "                print(\"L'immagine contiene il segnale di {}\".format(diz[i]['signal'].to_string()) + \". Il segnale è presente nella bounding box con probabilità pari a {}\".format(diz[i]['prob']))      \n",
    "                new_draw_rect(im, np.squeeze(diz[i]['new_bbox_coords']))\n",
    "            else:\n",
    "                print(\"L'immagine contiene il segnale di {}\".format(diz[i]['signal'].to_string()))\n",
    "                new_draw_rect(im, np.squeeze(diz[i]['new_bbox_coords']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_image_with_bboxes(img, diz):\n",
    "    image = np.squeeze(img).copy()\n",
    "    if len(diz)>0: #se il dizionario non è vuoto\n",
    "        formula = diz[list(diz.keys())[0]]['formula']\n",
    "        if formula == 'image[:40, 2*j:40 + 2*j,  :]':\n",
    "            for i in diz:\n",
    "                if i!='shape':\n",
    "                    j = diz[i]['j']\n",
    "                    image[:40, 2*j:40 + 2*j,  :] = draw_rect(diz[i]['array'], np.concatenate([diz[i]['bbox'], np.array([[0]])], axis = 1))\n",
    "\n",
    "        if formula == 'image[2*j:40 + 2*j, :40, :]':\n",
    "            for i in diz:\n",
    "                if i!='shape':\n",
    "                    j = diz[i]['j']\n",
    "                    image[2*j:40 + 2*j, :40, :] = draw_rect(diz[i]['array'], np.concatenate([diz[i]['bbox'], np.array([[0]])], axis = 1))\n",
    "\n",
    "        if formula == 'image[2*i : 40 + 2*i, 2*j:40 + 2*j,  :]':\n",
    "            for i in diz:\n",
    "                if i!='shape':\n",
    "                    k = diz[i]['i']\n",
    "                    j = diz[i]['j']\n",
    "                    image[2*k : 40 + 2*k, 2*j:40 + 2*j,  :] = draw_rect(diz[i]['array'], np.concatenate([diz[i]['bbox'], np.array([[0]])], axis = 1))\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_img(im):\n",
    "    multipli40 = np.arange(start = 40, stop = max(im.shape) + 40, step = 40)\n",
    "    index_x = np.argmin(np.absolute(multipli40-im.shape[1]))\n",
    "    new_x = multipli40[index_x]\n",
    "    index_y = np.argmin(np.absolute(multipli40-im.shape[0]))\n",
    "    new_y = multipli40[index_y]\n",
    "    resized = cv2.resize(im, (new_x, new_y), interpolation = cv2.INTER_AREA)\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_new_size(im, new_x, new_y, show= False):\n",
    "    new_im =  cv2.resize(im, (new_y, new_x), interpolation = cv2.INTER_AREA)\n",
    "    if show ==True:\n",
    "        plt.imshow(new_im); plt.show()\n",
    "    #new_im = reshape_img(new_im)\n",
    "    return new_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bbox_coords(diz):\n",
    "    if len(diz)>0:\n",
    "        formula = diz[list(diz.keys())[0]]['formula']\n",
    "        if (formula == 'image[2*i : 40 + 2*i, 2*j:40 + 2*j,  :]'):\n",
    "            for i in diz:\n",
    "                j = diz[i]['j']\n",
    "                k = diz[i]['i']\n",
    "                old_window = np.array([[0,0,40,40]])\n",
    "                new_window= np.array([[2*j, 2*k, 40 + 2*j, 40 + 2*k]])\n",
    "                difference = new_window - old_window\n",
    "                old_bbox_coords = diz[i]['bbox']\n",
    "                diz[i]['new_bbox_coords'] = old_bbox_coords + difference\n",
    "        if (formula == 'image[:40, 2*j:40 + 2*j,  :]'):\n",
    "            for i in diz:\n",
    "                j = diz[i]['j']\n",
    "                old_window = np.array([[0,0,40,40]])\n",
    "                new_window= np.array([[2*j, 0, 40 + 2*j, 40]])\n",
    "                difference = new_window - old_window\n",
    "                old_bbox_coords = diz[i]['bbox']\n",
    "                diz[i]['new_bbox_coords'] = old_bbox_coords + difference\n",
    "        if (formula == 'image[2*j:40 + 2*j, :40, :]'):\n",
    "            for i in diz:\n",
    "                j = diz[i]['j']\n",
    "                old_window = np.array([[0,0,40,40]])\n",
    "                new_window= np.array([[0, 2*j, 40, 40 + 2*j]])\n",
    "                difference = new_window - old_window\n",
    "                old_bbox_coords = diz[i]['bbox']\n",
    "                diz[i]['new_bbox_coords'] = old_bbox_coords + difference\n",
    "    return diz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_other_diz(img, size, euclidean):\n",
    "    img = np.squeeze(img).copy()\n",
    "    img = try_new_size(img, int(size[0]),int(size[1]))\n",
    "    shape = img.shape\n",
    "    img = np.expand_dims(img, axis = 0)\n",
    "    res_img = model_conv.predict(img)\n",
    "    #print(res_img)\n",
    "    diz = find_only_one_signal(res_img, euclidean)\n",
    "    diz = crops_with_signal(img, diz)\n",
    "    diz = multi_task_prediction(diz)\n",
    "    diz = add_bbox_coords(diz)\n",
    "    #if int(size[0]) == 120:\n",
    "        #plt.imshow(diz[list(diz.keys())[0]]['array']); plt.show()\n",
    "    diz['shape'] = shape\n",
    "    return diz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sizes(shape, iterations):\n",
    "    first = False\n",
    "    if shape[0]>shape[1]:\n",
    "        first = True\n",
    "    min_shape = min(shape)\n",
    "    ratio = max(shape)/min(shape)\n",
    "    difference_from_40 = min_shape - 40\n",
    "    list_of_shapes = []\n",
    "    for i in range(1, iterations + 1, 1):\n",
    "        if first == True:\n",
    "            list_of_shapes.append(((min_shape-difference_from_40)*i*ratio, (min_shape-difference_from_40)*i))\n",
    "        else:\n",
    "            list_of_shapes.append(((min_shape-difference_from_40)*i, (min_shape-difference_from_40)*i*ratio))\n",
    "    return list_of_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_control(original_diz, list_of_dict, euclidean):\n",
    "    new_diz = {}\n",
    "    original_shape = original_diz['shape']\n",
    "    for diz in list_of_dict:\n",
    "        if len(diz)>1:\n",
    "            for im in diz:\n",
    "                if (im!='shape'):\n",
    "                    ratiox = original_shape[0]/diz['shape'][0]\n",
    "                    ratioy = original_shape[1]/diz['shape'][1]\n",
    "                    x1 = np.squeeze(diz[im]['new_bbox_coords'])[0]*ratiox\n",
    "                    y1 = np.squeeze(diz[im]['new_bbox_coords'])[1]*ratioy\n",
    "                    x2 = np.squeeze(diz[im]['new_bbox_coords'])[2]*ratiox\n",
    "                    y2 = np.squeeze(diz[im]['new_bbox_coords'])[3]*ratioy\n",
    "                    bbox = np.array([[x1, y1, x2, y2]])\n",
    "                    min_dist = 10000\n",
    "                    dist = 10000\n",
    "                    found = False\n",
    "                    if len(original_diz) == 1:\n",
    "                        original_diz['im0'] = diz[im]\n",
    "                        original_diz['im0']['new_bbox_coords'] = bbox\n",
    "                        appoggio = original_diz.copy()\n",
    "                        original_diz = OrderedDict((k, appoggio[k]) for k in ['im0', 'shape'])\n",
    "                    #plt.imshow(diz[im]['array']); plt.show()\n",
    "                    for item in original_diz:\n",
    "                        if item!='shape':\n",
    "                            dist = distance.euclidean(original_diz[item]['new_bbox_coords'], bbox) #distanza tra le coordinate del dizionario originale e dell'item     \n",
    "                            #if diz['shape']==120:\n",
    "                                #print(dist)\n",
    "                            if dist<min_dist:\n",
    "                                min_dist = dist\n",
    "                                immagine = item\n",
    "                                found = True #è stata trovata una bbox nel dizionario corrente che contiene immagini sottoposte a resize   \n",
    "                    if found == True:\n",
    "                        if (min_dist <= euclidean)&(diz[im]['prob']>original_diz[immagine]['prob']):\n",
    "                            original_diz[immagine]= diz[im]\n",
    "                            original_diz[immagine]['new_bbox_coords'] = bbox\n",
    "                        if (min_dist>euclidean):\n",
    "                            key = 'im{}'.format(len(original_diz))\n",
    "                            original_diz[key] = diz[im]\n",
    "                            original_diz[key]['new_bbox_coords'] = bbox\n",
    "\n",
    "    return original_diz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dict(diz, euclidean):\n",
    "    if len(diz)>1:\n",
    "        new_d = {}\n",
    "        new_d[list(diz.keys())[0]] = {'prob':diz[list(diz.keys())[0]]['prob'], 'new_bbox_coords' : diz[list(diz.keys())[0]]['new_bbox_coords'], 'signal': diz[list(diz.keys())[0]]['signal']}       \n",
    "        for i in diz:\n",
    "            if i!='shape':\n",
    "                dist = 10000\n",
    "                min_dist = 10000\n",
    "                found = False\n",
    "                for item in new_d:\n",
    "                    dist = distance.euclidean(new_d[item]['new_bbox_coords'], diz[i]['new_bbox_coords']) #distanza tra le coordinate del dizionario originale e dell'item     \n",
    "                    if dist<min_dist:\n",
    "                        min_dist = dist\n",
    "                        immagine = item\n",
    "                        found = True        \n",
    "                if found == True:\n",
    "                    if (min_dist <= euclidean)&(diz[i]['prob']>new_d[immagine]['prob']):\n",
    "                        key = immagine\n",
    "                        d = {'prob': diz[i]['prob'],\n",
    "                            'signal': diz[i]['signal'],\n",
    "                            'new_bbox_coords': diz[i]['new_bbox_coords']}\n",
    "                        new_d[key] = d\n",
    "                    if (min_dist>euclidean):\n",
    "                        key = 'im{}'.format(len(new_d))\n",
    "                        d = {'prob': diz[i]['prob'],\n",
    "                            'signal': diz[i]['signal'],\n",
    "                            'new_bbox_coords': diz[i]['new_bbox_coords']}\n",
    "                        new_d[key] = d\n",
    "        return new_d\n",
    "    else:\n",
    "        return diz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execution(img, iterations = 12, return_shapes = False, euclidean = 15):\n",
    "    img = resize_img(img)\n",
    "    original_shape = img.shape\n",
    "    img = np.expand_dims(img, axis = 0)\n",
    "    res_img = model_conv.predict(img)\n",
    "    diz = find_only_one_signal(res_img, euclidean)\n",
    "    diz = crops_with_signal(img, diz)\n",
    "    diz = multi_task_prediction(diz)\n",
    "    diz = add_bbox_coords(diz)\n",
    "    diz['shape'] = original_shape\n",
    "    list_of_dict = []\n",
    "    list_of_shapes = generate_sizes(original_shape[0:2], iterations)\n",
    "    for i in list_of_shapes:\n",
    "        list_of_dict.append(create_other_diz(img, i, euclidean))\n",
    "        #print(len(list_of_shapes))\n",
    "    #controllo le bbox \n",
    "    new_d = bbox_control(diz, list_of_dict, euclidean)\n",
    "    new_d = clean_dict(new_d, euclidean)\n",
    "    if return_shapes == False:\n",
    "        return new_d, np.squeeze(img)\n",
    "    else:\n",
    "        return new_d, np.squeeze(img), list_of_shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dei dati & dei modelli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = np.load(r'C:\\Users\\Giobi\\OneDrive - Universita degli Studi di Milano-Bicocca\\Digital Signal and Image Management\\Progetto Segnali Stradali\\array_da_importare/train_speriamo_bene_completo_X.npy')\n",
    "y_1 = np.load(r'C:\\Users\\Giobi\\OneDrive - Universita degli Studi di Milano-Bicocca\\Digital Signal and Image Management\\Progetto Segnali Stradali\\array_da_importare/train_speriamo_bene_completo_Y.npy')\n",
    "X_train1, y_train1 = X_1, y_1\n",
    "X_train1 = X_train1/255\n",
    "df = pd.read_csv(r'C:\\Users\\Giobi\\OneDrive - Universita degli Studi di Milano-Bicocca\\Digital Signal and Image Management\\Progetto Segnali Stradali\\final_segnali_stradali.csv', sep = ';')\n",
    "X_test = np.load(r'C:\\Users\\Giobi\\OneDrive - Universita degli Studi di Milano-Bicocca\\Digital Signal and Image Management\\Progetto Segnali Stradali\\X_test.npy')\n",
    "y_test = np.load(r'C:\\Users\\Giobi\\OneDrive - Universita degli Studi di Milano-Bicocca\\Digital Signal and Image Management\\Progetto Segnali Stradali\\y_test.npy')\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_conv():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=8, kernel_size=7, strides=1, input_shape=(None,None,3))) #(None,None,3)\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters=16, kernel_size=9, strides=1))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "    model.add(Conv2D(filters=32, kernel_size=9, strides=1))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters = 64, kernel_size=5, strides=1))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters = 1, kernel_size=1, strides=1))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_multi_task():\n",
    "    visible = Input(shape=(40,40,3)) #(None,None,3)\n",
    "    x1 = Conv2D(16, kernel_size=3, strides=1)(visible)\n",
    "    x1 = LeakyReLU(alpha=0.1)(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x2 = Conv2D(32, kernel_size=3, strides=1)(x1)\n",
    "    x2 = LeakyReLU(alpha=0.1)(x2)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = MaxPooling2D(pool_size=(2, 2))(x2)\n",
    "    x3 = Conv2D(32, kernel_size=3, strides=1)(x2)\n",
    "    x3 = LeakyReLU(alpha=0.1)(x3)\n",
    "    x3 = BatchNormalization()(x3)\n",
    "    x4 = Conv2D(43, kernel_size=3, strides=1)(x3)\n",
    "    x4 = LeakyReLU(alpha=0.1)(x4)\n",
    "    x4 = BatchNormalization()(x4)\n",
    "    x4 = MaxPooling2D(pool_size=(2, 2))(x4)\n",
    "    x5 = Conv2D(43, kernel_size=1, strides=2)(x4)\n",
    "    x5 = LeakyReLU(alpha=0.1)(x5)\n",
    "    x5 = BatchNormalization()(x5)\n",
    "    x_f = Flatten()(x5)\n",
    "    x_1 = Dense(512, activation = 'relu')(x_f)\n",
    "    x_1 = Dropout(0.5)(x_1)\n",
    "    output1 = Dense(43, activation = 'softmax', name = 'classificazione') (x_1)\n",
    "    x_2 = Dense(512, activation = 'relu')(x_f)\n",
    "    x_2 = Dropout(0.5)(x_2)\n",
    "    output2 = Dense(4, activation='linear', name = 'regressione')(x_2)\n",
    "    model = Model(inputs=visible, outputs=[output1, output2])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = model_conv()\n",
    "model_conv.load_weights(r'C:\\Users\\Giobi\\OneDrive - Universita degli Studi di Milano-Bicocca\\Digital Signal and Image Management\\Progetto Segnali Stradali\\weights\\model_is_signal_conv.hdf5')\n",
    "model_multi_task = model_multi_task()\n",
    "model_multi_task.load_weights(r'C:\\Users\\Giobi\\OneDrive - Universita degli Studi di Milano-Bicocca\\Digital Signal and Image Management\\Progetto Segnali Stradali\\weights\\classificazione_multiclasse.hdf5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
